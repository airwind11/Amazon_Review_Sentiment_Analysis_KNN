{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from collections import Counter\n",
    "from stemming.porter2 import stem\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "def PreProcess_train_File(file):\n",
    "    with open(file,'r') as f:\n",
    "        df = pd.DataFrame(l.split(\"\\t\") for l in f) \n",
    "        newcols = {0: 'SentimentClass',1: 'Review',}\n",
    "        df.rename(columns=newcols, inplace=True)\n",
    "\n",
    "    clean = re.compile('<.*?>')\n",
    "    df[\"Review\"] = df[\"Review\"].apply(lambda x:re.sub(clean, ' ', x))\n",
    "    df[\"Review\"] = df[\"Review\"].str.lower().str.split()\n",
    "    stop = stopwords.words('english')\n",
    "\n",
    "    df[\"Review\"] = df[\"Review\"].apply(lambda x: [item for item in x if item not in stop])\n",
    "    df[\"Review\"] = df[\"Review\"].apply(lambda x: [re.sub(\"[^a-z]+\", \"\", word) for word in x if re.search(\"[^0-9]\",word)<>None])\n",
    "    df[\"Review\"] = df[\"Review\"].apply(lambda x:[stem(t) for t in x ])\n",
    "    print df.get_value(0,'Review')\n",
    "    return df\n",
    "\n",
    "def PreProcess_test_File(file):\n",
    "    with open(file,'r') as f:\n",
    "        df = pd.DataFrame(l for l in f) \n",
    "        newcols = {0: 'Review',}\n",
    "        df.rename(columns=newcols, inplace=True)\n",
    "\n",
    "    clean = re.compile('<.*?>')\n",
    "    df[\"Review\"] = df[\"Review\"].apply(lambda x:re.sub(clean, ' ', x))\n",
    "    df[\"Review\"] = df[\"Review\"].str.lower().str.split()\n",
    "    stop = stopwords.words('english')\n",
    "\n",
    "    df[\"Review\"] = df[\"Review\"].apply(lambda x: [item for item in x if item not in stop])\n",
    "    df[\"Review\"] = df[\"Review\"].apply(lambda x: [re.sub(\"[^a-z]+\", \"\", word) for word in x if re.search(\"[^0-9]\",word)<>None])\n",
    "    df[\"Review\"] = df[\"Review\"].apply(lambda x:[stem(t) for t in x ])\n",
    "    print df.get_value(0,'Review')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "idx = {}\n",
    "tid = 0\n",
    "nnz = 0\n",
    "ncols=0\n",
    "\n",
    "def build_common_index(combinedReview):\n",
    "    for d in combinedReview:\n",
    "        nnz += len(set(d))\n",
    "        for w in d:\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    ncols = len(idx)\n",
    "    \n",
    "def build_matrix(docs):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    nrows = len(docs)\n",
    "\n",
    "        \n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    \n",
    "    return mat\n",
    "\n",
    "\n",
    "def csr_info(mat, name=\"\", non_empy=False):\n",
    "    r\"\"\" Print out info about this CSR matrix. If non_empy, \n",
    "    report number of non-empty rows and cols as well\n",
    "    \"\"\"\n",
    "    if non_empy:\n",
    "        print(\"%s [nrows %d (%d non-empty), ncols %d (%d non-empty), nnz %d]\" % (\n",
    "                name, mat.shape[0], \n",
    "                sum(1 if mat.indptr[i+1] > mat.indptr[i] else 0 \n",
    "                for i in range(mat.shape[0])), \n",
    "                mat.shape[1], len(np.unique(mat.indices)), \n",
    "                len(mat.data)))\n",
    "    else:\n",
    "        print( \"%s [nrows %d, ncols %d, nnz %d]\" % (name, \n",
    "                mat.shape[0], mat.shape[1], len(mat.data)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale matrix and normalize its rows\n",
    "from collections import defaultdict\n",
    "def csr_idf(mat, copy=False, **kargs):\n",
    "    r\"\"\" Scale a CSR matrix by idf. \n",
    "    Returns scaling factors as dict. If copy is True, \n",
    "    returns scaled matrix and scaling factors.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # document frequency\n",
    "    df = defaultdict(int)\n",
    "    for i in ind:\n",
    "        df[i] += 1\n",
    "    # inverse document frequency\n",
    "    for k,v in df.items():\n",
    "        df[k] = np.log(nrows / float(v))  ## df turns to idf - reusing memory\n",
    "    # scale by idf\n",
    "    for i in range(0, nnz):\n",
    "        val[i] *= df[ind[i]]\n",
    "        \n",
    "    return df if copy is False else mat\n",
    "\n",
    "def csr_l2normalize(mat, copy=False, **kargs):\n",
    "    r\"\"\" Normalize the rows of a CSR matrix by their L-2 norm. \n",
    "    If copy is True, returns a copy of the normalized matrix.\n",
    "    \"\"\"\n",
    "    if copy is True:\n",
    "        mat = mat.copy()\n",
    "    nrows = mat.shape[0]\n",
    "    nnz = mat.nnz\n",
    "    ind, val, ptr = mat.indices, mat.data, mat.indptr\n",
    "    # normalize\n",
    "    for i in range(nrows):\n",
    "        rsum = 0.0    \n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            rsum += val[j]**2\n",
    "        if rsum == 0.0:\n",
    "            continue  # do not normalize empty rows\n",
    "        rsum = 1.0/np.sqrt(rsum)\n",
    "        for j in range(ptr[i], ptr[i+1]):\n",
    "            val[j] *= rsum\n",
    "            \n",
    "    if copy is True:\n",
    "        return mat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = PreProcess_train_File('train.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = PreProcess_test_File('test.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_Review_For_Commom_index = train_df[\"Review\"].extend(test_df[\"Review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mat = build_matrix(train_df[\"Review\"])\n",
    "test_mat = build_matrix(test_df[\"Review\"])\n",
    "train_mat_csr_idf = csr_idf(train_mat, copy=True)\n",
    "test_mat_csr_idf = csr_idf(test_mat, copy=True)\n",
    "train_mat_csr_idf_norm = csr_l2normalize(train_mat_csr_idf, copy=True)\n",
    "test_mat_csr_idf_norm = csr_l2normalize(test_mat_csr_idf, copy=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dp2 = np.dot(test_mat_csr_idf_norm,train_mat_csr_idf_norm.T)\n",
    "dp2 = np.dot(test_mat_csr_idf_norm[0],test_mat_csr_idf_norm[1].T)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
