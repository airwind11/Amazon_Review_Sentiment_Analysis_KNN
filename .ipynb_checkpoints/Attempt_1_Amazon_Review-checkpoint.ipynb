{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "# open docs file and read its lines\n",
    "with open(\"train.dat\", \"r\") as fh:\n",
    "    lines = fh.readlines()  \n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "lines[1]\n",
    "cnt = Counter(lines[1])\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stemming.porter2 import stem\n",
    "stem(\"enemy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "with open('train.dat','r') as f:\n",
    "    df = pd.DataFrame(l.split(\"\\t\") for l in f) \n",
    "    #print (df)\n",
    "    #print list(df)\n",
    "    #print df.loc[0]\n",
    "    newcols = {0: 'SentimentClass',1: 'Review',}\n",
    "    df.rename(columns=newcols, inplace=True)\n",
    "    #print list(df)\n",
    "    #print df.loc[0]\n",
    "    #print df.get_value(0,'Review')\n",
    "    #print df[\"Review\"]\n",
    "import re\n",
    "from stemming.porter2 import stem\n",
    "\n",
    "print df.get_value(0,'Review')\n",
    "clean = re.compile('<.*?>')\n",
    "df[\"Review\"] = df[\"Review\"].apply(lambda x:re.sub(clean, ' ', x))\n",
    "df[\"Review\"] = df[\"Review\"].str.lower().str.split()\n",
    "print df.get_value(0,'Review')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "#df[\"Review\"] = df[\"Review\"].apply(lambda x: [BeautifulSoup(item).get_text() for item in x])\n",
    "df[\"Review\"] = df[\"Review\"].apply(lambda x: [item for item in x if item not in stop])\n",
    "#df[\"Review\"] = df[\"Review\"].apply(lambda x: [re.sub(\"[^a-zA-Z]+\", \"\",item.replace(\",\", \"\").replace(\".\", \"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"/\",\"\")) for item in x if item not in stop])\n",
    "#df[\"Review\"] = df[\"Review\"].apply(lambda x :[word.replace(\",\", \"\").replace(\".\", \"\").replace(\"(\",\"\").replace(\")\",\"\").replace(\"/\",\"\") for word in x])   \n",
    "df[\"Review\"] = df[\"Review\"].apply(lambda x: [re.sub(\"[^a-z]+\", \"\", word) for word in x if re.search(\"[^0-9]\",word)<>None])\n",
    "df[\"Review\"] = df[\"Review\"].apply(lambda x:[stem(t) for t in x ])\n",
    "print df.get_value(0,'Review')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter(df.get_value(0,'Review'))\n",
    "keys = list(k for k,_ in cnt.items())\n",
    "keys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from scipy.sparse import csr_matrix\n",
    "def build_matrix(docs):\n",
    "    r\"\"\" Build sparse matrix from a list of documents, \n",
    "    each of which is a list of word/terms in the document.  \n",
    "    \"\"\"\n",
    "    nrows = len(docs)\n",
    "    idx = {}\n",
    "    tid = 0\n",
    "    nnz = 0\n",
    "    for d in docs:\n",
    "        nnz += len(set(d))\n",
    "        for w in d:\n",
    "            if w not in idx:\n",
    "                idx[w] = tid\n",
    "                tid += 1\n",
    "    ncols = len(idx)\n",
    "    \n",
    "        \n",
    "    # set up memory\n",
    "    ind = np.zeros(nnz, dtype=np.int)\n",
    "    val = np.zeros(nnz, dtype=np.double)\n",
    "    ptr = np.zeros(nrows+1, dtype=np.int)\n",
    "    i = 0  # document ID / row counter\n",
    "    n = 0  # non-zero counter\n",
    "    # transfer values\n",
    "    for d in docs:\n",
    "        cnt = Counter(d)\n",
    "        keys = list(k for k,_ in cnt.most_common())\n",
    "        l = len(keys)\n",
    "        for j,k in enumerate(keys):\n",
    "            ind[j+n] = idx[k]\n",
    "            val[j+n] = cnt[k]\n",
    "        ptr[i+1] = ptr[i] + l\n",
    "        n += l\n",
    "        i += 1\n",
    "            \n",
    "    mat = csr_matrix((val, ind, ptr), shape=(nrows, ncols), dtype=np.double)\n",
    "    mat.sort_indices()\n",
    "    \n",
    "    return mat\n",
    "\n",
    "\n",
    "def csr_info(mat, name=\"\", non_empy=False):\n",
    "    r\"\"\" Print out info about this CSR matrix. If non_empy, \n",
    "    report number of non-empty rows and cols as well\n",
    "    \"\"\"\n",
    "    if non_empy:\n",
    "        print(\"%s [nrows %d (%d non-empty), ncols %d (%d non-empty), nnz %d]\" % (\n",
    "                name, mat.shape[0], \n",
    "                sum(1 if mat.indptr[i+1] > mat.indptr[i] else 0 \n",
    "                for i in range(mat.shape[0])), \n",
    "                mat.shape[1], len(np.unique(mat.indices)), \n",
    "                len(mat.data)))\n",
    "    else:\n",
    "        print( \"%s [nrows %d, ncols %d, nnz %d]\" % (name, \n",
    "                mat.shape[0], mat.shape[1], len(mat.data)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = build_matrix(df[\"Review\"])\n",
    "csr_info(mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
